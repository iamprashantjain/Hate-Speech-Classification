{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"aritzia_reviews_v1.xlsx\", sheet_name='Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_rating', 'title', 'review_text', 'username', 'product_name',\n",
       "       'brand', 'link', 'category', 'price', 'scrape_date', 'review_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='review_rating'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['review_rating'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quality of fabric is low. Prefer the other leggings that are more durable and look more flattering.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['review_text'][33]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quality',\n",
       " 'of',\n",
       " 'fabric',\n",
       " 'is',\n",
       " 'low',\n",
       " '.',\n",
       " 'Prefer',\n",
       " 'the',\n",
       " 'other',\n",
       " 'leggings',\n",
       " 'that',\n",
       " 'are',\n",
       " 'more',\n",
       " 'durable',\n",
       " 'and',\n",
       " 'look',\n",
       " 'more',\n",
       " 'flattering',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quality', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fabric', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('low', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Prefer', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('leggings', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('are', 'VBP'),\n",
       " ('more', 'RBR'),\n",
       " ('durable', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('look', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('flattering', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Quality/NN\n",
      "  of/IN\n",
      "  fabric/NN\n",
      "  is/VBZ\n",
      "  low/JJ\n",
      "  ./.\n",
      "  Prefer/VB\n",
      "  the/DT\n",
      "  other/JJ\n",
      "  leggings/NNS\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  more/RBR\n",
      "  durable/JJ\n",
      "  and/CC\n",
      "  look/VB\n",
      "  more/JJR\n",
      "  flattering/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER( Valence aware dictionary and sentiment reasoner)\n",
    "\n",
    "- takes all words in sentence\n",
    "- it has a value of positive, begative or nuetral for each of these words\n",
    "- and combines all words value in the sentence and tells how positive, negative or nuetral the sentence\n",
    "- it doesnt account for relation between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\iampr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.607, 'neu': 0.393, 'pos': 0.0, 'compound': -0.4754}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I'm so unhappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.107, 'neu': 0.762, 'pos': 0.132, 'compound': 0.1263}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>username</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>So good!</td>\n",
       "      <td>Very form fitting, soft material. I recommend!</td>\n",
       "      <td>Lily C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Fits nicely I went up a size because I don’t l...</td>\n",
       "      <td>Perfect they have the right amount of stretch ...</td>\n",
       "      <td>KIM C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Love them</td>\n",
       "      <td>A tip I got in store was that the new sizing f...</td>\n",
       "      <td>Amanda M</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Super comfortable and so soft</td>\n",
       "      <td>Everything was amazing. I wish the pants game ...</td>\n",
       "      <td>simran G</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>Size 14 and fit a size 10</td>\n",
       "      <td>Jenesis V</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect Bag</td>\n",
       "      <td>This bag is great for everything from everyday...</td>\n",
       "      <td>Kristie H</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>Curator Bag is to die 4</td>\n",
       "      <td>Love!! Simple as that. You can dress it up and...</td>\n",
       "      <td>Trystan C</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5</td>\n",
       "      <td>Great everyday bag!</td>\n",
       "      <td>I've gotten so many compliments already! It's ...</td>\n",
       "      <td>Darine D</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it!!</td>\n",
       "      <td>Love everything about this bag!</td>\n",
       "      <td>Melissa G</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4</td>\n",
       "      <td>Love the bag, some flaws</td>\n",
       "      <td>The bag itself is sooo cute, and fits so much ...</td>\n",
       "      <td>Lazaya V</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-02-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_rating                                              title  \\\n",
       "0                5                                           So good!   \n",
       "1                5  Fits nicely I went up a size because I don’t l...   \n",
       "2                5                                          Love them   \n",
       "3                5                      Super comfortable and so soft   \n",
       "4                5                                              Great   \n",
       "..             ...                                                ...   \n",
       "495              5                                        Perfect Bag   \n",
       "496              5                            Curator Bag is to die 4   \n",
       "497              5                                Great everyday bag!   \n",
       "498              5                                          Love it!!   \n",
       "499              4                           Love the bag, some flaws   \n",
       "\n",
       "                                           review_text   username  \\\n",
       "0       Very form fitting, soft material. I recommend!     Lily C   \n",
       "1    Perfect they have the right amount of stretch ...      KIM C   \n",
       "2    A tip I got in store was that the new sizing f...   Amanda M   \n",
       "3    Everything was amazing. I wish the pants game ...   simran G   \n",
       "4                            Size 14 and fit a size 10  Jenesis V   \n",
       "..                                                 ...        ...   \n",
       "495  This bag is great for everything from everyday...  Kristie H   \n",
       "496  Love!! Simple as that. You can dress it up and...  Trystan C   \n",
       "497  I've gotten so many compliments already! It's ...   Darine D   \n",
       "498                    Love everything about this bag!  Melissa G   \n",
       "499  The bag itself is sooo cute, and fits so much ...   Lazaya V   \n",
       "\n",
       "                                product_name    brand  \\\n",
       "0    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "1    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "2    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "3    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "4    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "..                                       ...      ...   \n",
       "495                       curator bigger bag  Babaton   \n",
       "496                       curator bigger bag  Babaton   \n",
       "497                       curator bigger bag  Babaton   \n",
       "498                       curator bigger bag  Babaton   \n",
       "499                       curator bigger bag  Babaton   \n",
       "\n",
       "                                                  link    category  price  \\\n",
       "0    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "1    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "2    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "3    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "4    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "..                                                 ...         ...    ...   \n",
       "495  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "496  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "497  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "498  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "499  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "\n",
       "    scrape_date review_date  \n",
       "0    2025-02-06  2025-01-23  \n",
       "1    2025-02-06  2025-01-06  \n",
       "2    2025-02-06  2025-01-06  \n",
       "3    2025-02-06  2025-01-06  \n",
       "4    2025-02-06  2025-01-06  \n",
       "..          ...         ...  \n",
       "495  2025-02-06  2024-04-06  \n",
       "496  2025-02-06  2024-03-06  \n",
       "497  2025-02-06  2024-03-06  \n",
       "498  2025-02-06  2025-02-06  \n",
       "499  2025-02-06  2025-02-06  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af39a0710d642d1b720b3324d6d478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list to store results\n",
    "res = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    review_text = row['review_text']\n",
    "    score = sia.polarity_scores(review_text)\n",
    "    \n",
    "    # Convert row to dictionary and add sentiment scores\n",
    "    row_dict = row.to_dict()  # Convert the row to a dictionary\n",
    "    row_dict.update({\n",
    "        'neg': score['neg'],\n",
    "        'neu': score['neu'],\n",
    "        'pos': score['pos'],\n",
    "        'compound': score['compound']\n",
    "    })\n",
    "    \n",
    "    res.append(row_dict)\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>username</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>review_date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>So good!</td>\n",
       "      <td>Very form fitting, soft material. I recommend!</td>\n",
       "      <td>Lily C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Fits nicely I went up a size because I don’t l...</td>\n",
       "      <td>Perfect they have the right amount of stretch ...</td>\n",
       "      <td>KIM C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.7530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Love them</td>\n",
       "      <td>A tip I got in store was that the new sizing f...</td>\n",
       "      <td>Amanda M</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.9498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Super comfortable and so soft</td>\n",
       "      <td>Everything was amazing. I wish the pants game ...</td>\n",
       "      <td>simran G</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>Size 14 and fit a size 10</td>\n",
       "      <td>Jenesis V</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating                                              title  \\\n",
       "0              5                                           So good!   \n",
       "1              5  Fits nicely I went up a size because I don’t l...   \n",
       "2              5                                          Love them   \n",
       "3              5                      Super comfortable and so soft   \n",
       "4              5                                              Great   \n",
       "\n",
       "                                         review_text   username  \\\n",
       "0     Very form fitting, soft material. I recommend!     Lily C   \n",
       "1  Perfect they have the right amount of stretch ...      KIM C   \n",
       "2  A tip I got in store was that the new sizing f...   Amanda M   \n",
       "3  Everything was amazing. I wish the pants game ...   simran G   \n",
       "4                          Size 14 and fit a size 10  Jenesis V   \n",
       "\n",
       "                              product_name   brand  \\\n",
       "0  BUTTER New Cheeky Flare Hi-Rise Legging  Golden   \n",
       "1  BUTTER New Cheeky Flare Hi-Rise Legging  Golden   \n",
       "2  BUTTER New Cheeky Flare Hi-Rise Legging  Golden   \n",
       "3  BUTTER New Cheeky Flare Hi-Rise Legging  Golden   \n",
       "4  BUTTER New Cheeky Flare Hi-Rise Legging  Golden   \n",
       "\n",
       "                                                link    category  price  \\\n",
       "0  https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "1  https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "2  https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "3  https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "4  https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "\n",
       "  scrape_date review_date    neg    neu    pos  compound  \n",
       "0  2025-02-06  2025-01-23  0.000  0.642  0.358    0.4199  \n",
       "1  2025-02-06  2025-01-06  0.041  0.795  0.163    0.7530  \n",
       "2  2025-02-06  2025-01-06  0.053  0.540  0.407    0.9498  \n",
       "3  2025-02-06  2025-01-06  0.099  0.680  0.221    0.5574  \n",
       "4  2025-02-06  2025-01-06  0.000  0.667  0.333    0.3612  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='review_rating', ylabel='compound'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAG3CAYAAABSTJRlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtHElEQVR4nO3dfVTUdf7//8eMDHJhAxIQEIoQIvbJ8io30VKj0jx+Sk0trc/WtrnZuutnP5+z5qpHxW/Zhlmf2rRs063s5FUkVkpmF5olbmpmRV6gWXmBKKQjKYqMM78/WufnCLgwDM744n47p3N4vS+f42uUR6/36/1+W9xut1sAAACGsga6AAAAgKZE2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARgsJdAHnW7Vqld599105HA6lpKTowQcfVHp6ep3br1y5UqtXr1Z5ebnsdrt+9atfadSoUQoNDb2IVQMAgGAVVCM7hYWFWrBggYYNG6bc3FylpKRoxowZOnbsWK3bf/bZZ1q4cKGGDx+u//u//9OYMWO0YcMGLVq06CJXDgAAglVQjeysWLFC2dnZ6tevnyRp9OjR2rJli9asWaPBgwfX2H7nzp3q0KGDevfuLUmKj49Xr169tGvXrgaf++jRo3I6nY2qHwAAXBwhISFq3bp1/bZt4lrqzel0as+ePV6hxmq1qlOnTiouLq51nw4dOujTTz/V7t27lZ6erkOHDunLL7/UjTfeWOd5qqurVV1d7WlbLBaFh4fL6XQSdgAAMFDQhJ2Kigq5XC5FR0d7LY+OjlZJSUmt+/Tu3VsVFRWaMmWKJOnMmTO69dZbNXTo0DrPk5+fr7y8PE87NTVVubm5iouLa/yHAAAAQSdowo4vvv32W+Xn5+uhhx5S+/btVVpaqldeeUV5eXkaNmxYrfsMGTJEgwYN8rQtFoskqaysjJEdAAAuESEhIfUeqAiasGO322W1WuVwOLyWOxyOGqM9Zy1ZskQ33XSTsrOzJUlt27bVqVOn9Pe//11Dhw6V1Vpz/rXNZpPNZqv1eG63u1GfAQAABJ+guRsrJCREaWlpKioq8ixzuVwqKipSRkZGrftUVVV5RmbOqi3gAACA5itoRnYkadCgQZozZ47S0tKUnp6ugoICVVVVqW/fvpKk2bNnKyYmRqNGjZIkdevWTStXrlRqaqrnMtaSJUvUrVs3Qg8AAJAUZGEnKytLFRUVWrp0qRwOh9q1a6dJkyZ5LmOVl5d7jeTcddddslgsWrx4sY4cOSK73a5u3bpp5MiRAfoEAAAg2FjcTFSR9MsE5XNvSQcAAMHLZrPVe4Iy13oAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABgtqG49BwAATcvtdquystLTjoiIqPGAXtMQdgAAaEYqKys1ZswYT3vu3LmKjIwMYEVNj8tYAADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBoPEEZAIAmcHD8Q4EuoVYnXW6v9qGp4xRuDa7XRSQ+Nc+vx2NkBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABG491YAAA0I2EWaXp8qFfbdIQdAECTcrvdqqys9LQjIiJksTSD37BBymKxKLyZ/fETdgAATaqyslJjxozxtOfOnavIyMgAVoTmhjk7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBoIYEu4HyrVq3Su+++K4fDoZSUFD344INKT0+vc/sTJ05o0aJF2rhxo44fP664uDjdf//96tq160WsGgAABKugCjuFhYVasGCBRo8erfbt22vlypWaMWOGnn32WUVFRdXY3ul06vHHH5fdbtf//u//KiYmRuXl5YqIiAhA9QAAIBgFVdhZsWKFsrOz1a9fP0nS6NGjtWXLFq1Zs0aDBw+usf3HH3+s48eP67HHHlNIyC8fJT4+/mKWDABB5eD4hwJdQg0nXW6v9qGp4xRutQSomrolPjUv0CWgiQRN2HE6ndqzZ49XqLFarerUqZOKi4tr3eeLL75Q+/btNX/+fG3evFl2u129evXS4MGDZbXWPh2purpa1dXVnrbFYlF4eLjnZwBA88TvgODh774ImrBTUVEhl8ul6Ohor+XR0dEqKSmpdZ9Dhw6prKxMvXv31sSJE1VaWqp58+bpzJkzGj58eK375OfnKy8vz9NOTU1Vbm6u4uLi/PZZACBQav/XEvWRmJjo1+PRF77zd18ETdjxhdvtlt1u18MPPyyr1aq0tDQdOXJE77zzTp1hZ8iQIRo0aJCnfTY9lpWVyel0XpS6AQDB5+DBg4EuAf9Sn74ICQmp90BF0IQdu90uq9Uqh8PhtdzhcNQY7TkrOjpaISEhXpesrrzySjkcDjmdTs88nnPZbDbZbLZaj+d2u2tdDgAwH78Dgoe/+yJonrMTEhKitLQ0FRUVeZa5XC4VFRUpIyOj1n06dOig0tJSuVwuz7KDBw+qdevWtQYdAADQ/ARN2JGkQYMG6aOPPtLatWu1f/9+zZs3T1VVVerbt68kafbs2Vq4cKFn+9tuu03Hjx/Xq6++qpKSEm3ZskX5+fnq379/gD4BAAAINkE1/JGVlaWKigotXbpUDodD7dq106RJkzyXscrLy71maMfGxmry5Ml67bXXNH78eMXExOj222+v9TZ1AADQPAVV2JGkAQMGaMCAAbWuy8nJqbEsIyNDM2bMaOKqAADApSqoLmMBAAD4G2EHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYLSQQBcAAE3B7XarsrLS046IiJDFYglgRQAChbADwEiVlZUaM2aMpz137lxFRkYGsCIAgcJlLAAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGC0kEAXAAAwW5hFmh4f6tUGLibCDgCgSVksFoUTcBBAhB3Aj9xutyorKz3tiIgIWSz8Kw8AgUTYAfyosrJSY8aM8bTnzp2ryMjIAFYEAGCCMgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYLqe+G5eXlPp0gNjbWp/0AAAD8od5hZ+zYsT6dYMmSJT7tBwAA4A/1DjuPPPKIV9vtdqugoEDl5eXq3bu3kpKSJEkHDhzQ+vXrFRcXp9tvv92/1QIAADRQvcNO3759vdrLli1TdXW1/va3v+myyy7zWjdixAhNmTJFDofDHzUCAAD4zOcJyh988IFuueWWGkFHkux2u7Kzs7V69Wqfjr1q1SqNHTtW9957ryZNmqTdu3fXa7/169drxIgRmjlzpk/nBQAA5vE57Pz888+qqqqqc/3p06d1/PjxBh+3sLBQCxYs0LBhw5Sbm6uUlBTNmDFDx44du+B+hw8f1uuvv66OHTs2+JwAAMBc9b6Mdb727duroKBAXbp0UVpamte67777TgUFBUpPT2/wcVesWKHs7Gz169dPkjR69Ght2bJFa9as0eDBg2vdx+Vy6fnnn9eIESO0fft2nThxosHnBeC7g+MfCnQJNZx0ub3ah6aOU7jVEqBq6pb41LxAlwAYz+ew89vf/lY5OTmaOHGiMjIylJCQIEkqLS1VcXGxWrVqpQcffLBBx3Q6ndqzZ49XqLFarerUqZOKi4vr3C8vL092u10333yztm/ffsFzVFdXq7q62tO2WCwKDw/3/Aw0xvnfIYvFwvcKF8T3I3jQF8HD333hc9hJTk7WrFmztHz5cm3dulV79uyRJMXFxWngwIG68847FR0d3aBjVlRUyOVy1dgvOjpaJSUlte6zY8cOffzxx/Wep5Ofn6+8vDxPOzU1Vbm5uYqLi2tQrUBtzr90m5CQoFatWgWomoun9r+dqI/ExES/Ho++8B19ETz83Rc+hx3plxDywAMP+KmUhjt58qSef/55Pfzww7Lb7fXaZ8iQIRo0aJCnfTY9lpWVyel0NkmdaD7Ov4RaWlqqyMjIAFWDS8HBgwcDXQL+hb4IHvXpi5CQkHoPVDQq7Pib3W6X1Wqtccu6w+GodZTo0KFDKisrU25urmeZ2/3Ldfp77rlHzz77rOfy2lk2m002m63W85/dF/DV+d8ht9vN9woXxPcjeNAXwcPffdGosLN//36tXbtWhw4d0okTJ2oUZ7FYNHXq1PoXExKitLQ0FRUVqUePHpJ+mXxcVFSkAQMG1Ng+KSlJs2bN8lq2ePFinTp1Sg888ACvqgAAAL6HnXXr1umFF15QixYtlJSUVOu8BF+S2aBBgzRnzhylpaUpPT1dBQUFqqqq8jzUcPbs2YqJidGoUaMUGhqqtm3beu1/9pLB+csBAEDz5HPYefPNN5WamqqJEyfWe75MfWRlZamiokJLly6Vw+FQu3btNGnSJM9lrPLycmbMAwCAevM57Bw5ckT/+Z//6degc9aAAQNqvWwlSTk5ORfc19cXlgIAADP5/ATllJQUHTlyxJ+1AAAA+J3PYefXv/611qxZo507d/qzHgAAAL/y+TLW22+/rYiICE2dOlXJycmKjY2V1eqdnSwWix599NFGFwkAAOArn8PO3r17JUmxsbE6deqU9u/fX2MbJhIDAIBA8znszJkzx591AAAANAmf5+wAAABcCnwe2SkvL6/XdjzFGAAABJLPYae+z7NZsmSJr6cAAABoNJ/DziOPPFJjmcvlUllZmdatWye73a7+/fs3qjgAAIDG8jnsnH1XVW3uvPNOTZ48WZWVlb4eHgAAwC+aZIJyWFiY+vbtq5UrVzbF4QEAAOqtye7GcrvdcjgcTXV4AACAevH5MlZdKisrtX37dr3zzjtKTU319+EBAAAaxOewc/fdd19wfWxsrB566CFfDw9c0MHxwfndOulye7UPTR2ncGvwPUk88al5gS4BAC4an8POXXfdVeN1EBaLRZGRkbriiit03XXXqUWLFo0uEAAAoDF8DjsjRozwZx0AAABNwi9zdk6dOuV5onJsbKzCwsL8cVgAAIBGa1TY2b17t9544w3t2LFDLpdLkmS1WpWZman77rtPV111lV+KBAAA8JXPYWfXrl3KyclRSEiIbr75Zl155ZWSpAMHDmj9+vWaNm2acnJylJ6e7rdiAQAAGsrnsLN48WLFxMToscceU3R0tNe64cOHa8qUKVq0aJGmTJnS2BoBAAB85vNDBXft2qVbb721RtCRpOjoaN1yyy3atWtXY2oDAABoNJ/DjsVi0ZkzZ+pc73K5atyaDgAAcLH5HHY6dOig999/X2VlZTXWlZeXa/Xq1crMzGxUcQAAAI3l85ydkSNHatq0afrTn/6kHj16KDExUZJUUlKizZs3q0WLFho5cqTfCgUAAPCFz2EnNTVVTzzxhBYtWqTNmzfr9OnTkqTQ0FB17txZ99xzj5KTk/1WKAAAgC8a9Zyd5ORkjR8/Xi6XSxUVFZIku90uq7XJXqYOAADQIH55grLFYvFMRmZSMgAACCaNCjv79+/XkiVL9NVXX6mqqkqS1LJlS1133XUaPny42rZt65ciAQAAfOVz2Nm+fbueeOIJud1ude/eXUlJSZL+/wnKW7du1aRJk9SxY0e/FQsAANBQPoed1157TVFRUcrJyVFsbKzXuvLyck2bNk0LFizQX//610YXCQAA4CufZxLv27dPt912W42gI/3y5vPbbrtN+/bta1RxAAAAjeVz2ImLi5PT6axzvdPp1OWXX+7r4QEAAPzC57AzbNgwvffee/rhhx9qrPv++++1atUqDR8+vDG1AQAANJrPc3aKi4sVFRWlCRMmqEOHDkpISJAkHTx4UMXFxWrbtq2Ki4tVXFzs2cdiseg3v/lN46sGAACoJ5/Dzvvvv+/5eefOndq5c6fX+r1792rv3r019iPsAACAi8nnsLNkyRJ/1gEAANAkeK8DAAAwml9eF+FyuVRZWVnrulatWvnjFAAAAD7xOew4nU69/fbbWrNmjX766Se5XK5at+NyFwAACCSfw87f//53ffLJJ8rIyND111+viIgIf9YFAADgFz6HnX/+85+66aabNHbsWH/WAwAA4Fc+T1Bu2bKl2rdv789aAAAA/M7nsNOrVy9t2bLFn7UAAAD4nc+Xse677z698MILevLJJ9WvXz9dfvnlslprZqe0tLRGFQgAANAYPoed6upqud1uffnll/ryyy/r3I67sQAAQCD5HHZefPFFbdy4Ub169VJ6ejp3YwEAgKDkc9j56quvNGDAAD3wwAN+LAcAAMC/fJ6gHB4e7nnTOQAAQLDyeWQnOztb69ev12233VbrxGQACKQwizQ9PtSrDaB58jnsJCcna/PmzZowYYL69OlT591Yv/rVrxpVIAD4wmKxKJyAA0CNCDvPPvus5+fXX3+9zu24GwsAAASSz2Fn2rRp/qwDAACgSfgcdq6++mp/1gEAANAkfA4759q/f7/KysokSXFxcUpOTvbHYQEAABqtUWFn06ZNWrBggQ4fPuy1PD4+Xvfff7+6d+/eqOIAAAAay+ews2XLFj399NOKi4vTyJEjPaM5+/fv10cffaRZs2bpL3/5izp37uyvWgEAABrM57Dz1ltvKSUlRdOnT1dYWJhneffu3TVgwABNnTpVb775JmEHAAAElM9PA9y7d6/69OnjFXTOCgsLU9++fbV3795GFQcAANBYPocdm82m48eP17n++PHjstlsvh4eAADAL3wOO9dcc40KCgpUXFxcY92uXbv03nvvqVOnTo0qDgAAoLF8nrNz3333afLkyZoyZYrS09OVlJQkSSopKdHu3bsVFRWle++912+FAgAA+MLnsBMfH69Zs2YpPz9fW7duVWFhoaRfnrMzcOBADR48WFFRUX4rFAAAwBc+h50zZ87IZrPpgQceqHV9ZWWlzpw5oxYtWvh6CgAAgEbzec7OK6+8oilTptS5fsqUKVqwYIGvhwcAAPALn0d2tm7dqptuuqnO9TfccIM+/fRT/eY3v2nwsVetWqV3331XDodDKSkpevDBB5Wenl7rth9++KHWrVunffv2SZLS0tI0cuTIOrcHAADNi88jO0ePHlVMTEyd61u3bq0jR440+LiFhYVasGCBhg0bptzcXKWkpGjGjBk6duxYrdtv27ZNvXr10rRp0/T444/r8ssv1+OPP+7TuQEAgHl8DjutWrVSSUlJnesPHDig8PDwBh93xYoVys7OVr9+/ZScnKzRo0crNDRUa9asqXX7cePGqX///mrXrp2uvPJKjRkzRm63W998802Dzw0AAMzj82Wszp0768MPP9SNN96o1NRUr3V79uzRhx9+qJ49ezbomE6nU3v27NHgwYM9y6xWqzp16lTr83xqU1VVJafTqVatWtW6vrq6WtXV1Z62xWLxhDKLxdKgeoFLFd/14EFfBA/6Inj4uy98Djt33323tm7dqkmTJqlbt25q06aNJGnfvn364osvZLfbdffddzfomBUVFXK5XIqOjvZaHh0dfcFRpHO98cYbiomJqfOBhvn5+crLy/O0U1NTlZubq7i4uAbVisCq37cBdUlMTPTr8egP39EXwYO+CB7+7gufw05MTIyefPJJvfHGG9q8ebM2bdokSQoPD1fv3r01cuTIC87paQrLly/X+vXrlZOTo9DQ0Fq3GTJkiAYNGuRpn02PZWVlcjqdF6VOINAOHjwY6BLwL/RF8KAvgkd9+iIkJKTeAxU+hx3pl0nIf/jDH+R2u1VRUSFJstvtPg8/2e12Wa1WORwOr+UOh6PGaM/53nnnHS1fvlxTpkxRSkpKndvZbLY639nldrsbWjJwSeK7Hjzoi+BBXwQPf/eFzxOUz2WxWBQVFaWoqKhGXWcLCQlRWlqaioqKPMtcLpeKioqUkZFR535vv/223nrrLU2aNElXXXWVz+cHAADm8UvY8adBgwbpo48+0tq1a7V//37NmzdPVVVV6tu3ryRp9uzZWrhwoWf75cuXa8mSJXrkkUcUHx8vh8Mhh8OhU6dOBegTAACAYNKoy1hNISsrSxUVFVq6dKkcDofatWunSZMmeS5jlZeXe40effDBB3I6nXrmmWe8jjNs2DCNGDHiYpYOKMwiTY8P9WoDAAIr6MKOJA0YMEADBgyodV1OTo5Xe86cORehIqB+LBaLwgk4ABBUgu4yFgAAgD8RdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYLCXQBaDy3263KykpPOyIiQhaLJYAVAQAQPAg7BqisrNSYMWM87blz5yoyMjKAFQEAEDy4jAUAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaCGBLqA2q1at0rvvviuHw6GUlBQ9+OCDSk9Pr3P7DRs2aMmSJSorK1NCQoLuvfdede3a9SJWDAAAglXQjewUFhZqwYIFGjZsmHJzc5WSkqIZM2bo2LFjtW6/c+dOPffcc7r55puVm5ur66+/Xk899ZT27t17kSsHAADBKOjCzooVK5Sdna1+/fopOTlZo0ePVmhoqNasWVPr9gUFBercubPuuOMOJScn65577lFaWppWrVp1kSsHAADBKKguYzmdTu3Zs0eDBw/2LLNarerUqZOKi4tr3ae4uFiDBg3yWnbddddp06ZNtW5fXV2t6upqT9tisSg8PNzz86Xo/LotFssl+1lwcfD9CB70RfCgL4KHv/siqMJORUWFXC6XoqOjvZZHR0erpKSk1n0cDoeioqK8lkVFRcnhcNS6fX5+vvLy8jzt1NRU5ebmKi4u7t/W98W9A//tNoFw0uX2apdO+aPCrcH3l7bbGwV+O1aiH4+FxqM/ggd9ETzoi+ARVGHnYhgyZIjXSNDZ9FhWVian0xmospqFgwcPBroEAIAhQkJC6jVQIQVZ2LHb7bJarTVGZRwOR43RnrOio6NrTF4+duxYndvbbDbZbLZa17nd7lqXwz/48wUABEJQTVAOCQlRWlqaioqKPMtcLpeKioqUkZFR6z4ZGRn65ptvvJZ9/fXXat++fZPWCgAALg1BNbIjSYMGDdKcOXOUlpam9PR0FRQUqKqqSn379pUkzZ49WzExMRo1apQkaeDAgcrJydG7776rrl27av369fruu+/0u9/9zu+1JT41z+/H9IcTJ05IY8Z42lf8v78pMjIygBUBABA8gi7sZGVlqaKiQkuXLpXD4VC7du00adIkz2Wp8vJyr1naHTp00Lhx47R48WItWrRIiYmJGj9+vNq2bRugTwAAAIKJxc1ECkm/TFA+95b0S8mJEyc05pyRnblz5zKyAwAwms1mq/cE5aCaswMAAOBvhB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjWdxutzvQRQSDsrIyVVdXB7oMn7jdblVWVnraERERslgsAawIAICmZbPZFBcXV69tQ5q4FlwEFotFkZGRgS4DAICgxGUsAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNd2P9S0gIfxQAAFwqGvJ7m7eeAwAAo3EZyxAnT57UhAkTdPLkyUCX0uzRF8GDvgge9EVwaW79QdgxhNvt1vfffy8G6gKPvgge9EXwoC+CS3PrD8IOAAAwGmEHAAAYjbBjCJvNpmHDhslmswW6lGaPvgge9EXwoC+CS3PrD+7GAgAARmNkBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Xj75SVu27Zteuedd/T999/r6NGj+vOf/6wePXoEuqxmKT8/Xxs3btSBAwcUGhqqjIwM3XfffUpKSgp0ac3O6tWrtXr1apWVlUmSkpOTNWzYMHXp0iXAlWH58uVauHChBg4cqAceeCDQ5TQrS5cuVV5enteypKQkPfvss4Ep6CIi7Fziqqqq1K5dO918882aNWtWoMtp1rZt26b+/fvrqquu0pkzZ7Ro0SI9/vjjeuaZZxQWFhbo8pqVmJgYjRo1SomJiXK73frkk080c+ZMzZw5U23atAl0ec3W7t279cEHHyglJSXQpTRbbdq00ZQpUzxtq7V5XOAh7FziunTpwv+tBonJkyd7tceOHauHHnpIe/bs0dVXXx2gqpqn7t27e7VHjhyp1atXa9euXYSdADl16pSef/55Pfzww1q2bFmgy2m2rFaroqOjA13GRUfYAZpIZWWlJKlVq1YBrqR5c7lc2rBhg6qqqpSRkRHocpqtefPmqUuXLrr22msJOwFUWlqqhx9+WDabTRkZGRo1apRiY2MDXVaTI+wATcDlcunVV19Vhw4d1LZt20CX0yzt3btXkydPVnV1tcLCwvTnP/9ZycnJgS6rWVq/fr2+//57/fWvfw10Kc1a+/bt9fvf/15JSUk6evSo8vLyNHXqVD399NMKDw8PdHlNqnlcrAMusvnz52vfvn3605/+FOhSmq2kpCQ99dRTeuKJJ3Tbbbdpzpw52r9/f6DLanbKy8v16quvaty4cQoNDQ10Oc1aly5d1LNnT6WkpKhz586aOHGiTpw4oQ0bNgS6tCbHyA7gZ/Pnz9eWLVs0ffp0XX755YEup9kKCQlRQkKCJCktLU3fffedCgoK9Lvf/S7AlTUve/bs0bFjxzRhwgTPMpfLpe3bt2vVqlVauHBhs5kkG2wiIyOVlJSk0tLSQJfS5Ag7gJ+43W794x//0MaNG5WTk6P4+PhAl4RzuFwuVVdXB7qMZqdTp0417hR98cUXlZSUpDvvvJOgE0CnTp1SaWmpbrzxxkCX0uQIO5e4s1/Wsw4fPqwffvhBrVq1ahaTzoLJ/Pnz9dlnn+nRRx9VeHi4HA6HJCkiIoLh+4ts4cKF6ty5s2JjY3Xq1Cl99tln2rZtW4075tD0wsPDa8xba9mypS677DLms11kCxYsUPfu3RUbG6ujR49q6dKlslqt6t27d6BLa3KEnUvcd999p+nTp3vaCxYskCT16dNHY8eODVRZzdLq1aslSTk5OV7Lf//736tv374Xv6Bm7NixY5ozZ46OHj2qiIgIpaSkaPLkybr22msDXRoQMEeOHNFzzz2nn3/+WXa7XZmZmZoxY4bsdnugS2tyFrfb7Q50EQAAAE2Fi6UAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAumpycnBpPmDbZ2rVrNWLECB0+fDjQpQDNGmEHABpp2bJl2rhxY6DLAFAHXhcB4KJxOp2SpJAQs17L91//9V+64YYbaryPzuVyyel0ymazyWKxBKg6AIzsAKjVqVOn/H7MkJCQoA86LpdLp0+f9suxrFarQkNDCTpAgDGyA0BLly5VXl6ennnmGb311lvaunWr4uLiNHPmTK1bt04rV67U/v37FRoaquuuu0733XefYmNjJUnz58/X2rVrNW/ePLVs2dLruM8++6y+/fZbvfTSS7JarZ75OufO26murlZ+fr4+/fRT/fTTT4qKilKvXr109913y2azSZJmzZqlsrIy5ebmevZ78skntWXLFj366KPq3r27JGnXrl2aPHmyJk6cqC5dutTrs48YMUL9+/dXRkaG8vPzdfDgQf3P//yPevTooXfeeUcbN25USUmJqqqqlJycrCFDhuiGG27w2v98ffr00dixY7V27Vq98MILmj17tuLj4yVJY8eOVZs2bTR48GC99tpr2rt3r1q3bq3hw4erT58+Xsf58ccf9Y9//EO7d+/WZZddpltvvVUxMTF68cUXvY4J4MKC+3+xAFxUzzzzjBISEjRy5Ei53W4tW7ZMS5YsUc+ePZWdna2Kigq99957mjZtmmbOnKnIyEhlZWXp/fff15YtW9SzZ0/PsaqqqvTFF1+ob9++slprH0R2uVyaOXOmduzYoezsbCUnJ2vv3r1auXKlSkpK9Oijj0qSMjMztWnTJlVWVioiIkJut1s7d+6UxWLR9u3bPWFn+/btslgs6tChQ4M+d1FRkTZs2KABAwbosssu84SI9957T926dVPv3r3ldDpVWFioZ555Rn/5y1/UtWtXSdIf/vAHvfTSS0pPT1d2drYkKSEh4YLnKy0t1dNPP62bb75Zffr00Zo1a/TCCy8oLS1Nbdq0kSQdOXJE06dPl8Vi0ZAhQ9SyZUt9/PHHQT8yBgQj/tYA8EhJSdF///d/S5LKysr0xz/+UXfffbeGDh3q2aZHjx6aMGGC3n//fQ0dOlSZmZmKiYlRYWGhV9jZsmWLqqqqlJWVVef5PvvsM3399deaPn26MjMzPcvbtGmjl19+WTt37lSHDh3UsWNHT8Dp0qWL9u3bpxMnTuiGG27Qjh07PPvt2LFD7dq1U0RERIM+d0lJiZ5++mklJyd7LX/uuecUGhrqaQ8YMEATJkzQihUrPGHnpptu0ssvv6z4+HjddNNN9T7f9OnT1bFjR0lSVlaWHnnkEa1Zs0a//vWvJUnLly/XiRMnlJubq3bt2kmS+vXrp3HjxjXoswFgzg6Ac9x6662enz///HO53W5lZWWpoqLC8190dLQSEhL07bffSpIsFotuuOEGffnll17zfAoLCxUTE+MVYs73z3/+U8nJyUpKSvI6xzXXXCNJnnOkpqYqLCxM27dvl/TLCM7ll1+uPn36aM+ePaqqqpLb7daOHTsueL66XH311TWCjiSvoHP8+HFVVlaqY8eO+v777xt8jnMlJyd7go4k2e12JSUled2i/tVXXykjI8MTdCSpVatW6t27d6PODTRHjOwA8Dh3DkhpaancbnedIwnnXk7JyspSQUGBNm/erN69e+vUqVP68ssvdcstt1xwcu7Bgwd14MABPfTQQ7WuP3bsmKRfJvpmZGR4hZ3MzExlZmbK5XJp165dioqK0vHjx71ChC+f+1xffPGFli1bph9++EHV1dWe5Y2dcHx2vtO5IiMjdeLECU+7rKxM7du3r7Hdv7tEBqAmwg4Aj3NHMlwulywWiyZOnFjrnJuwsDDPzxkZGYqLi1NhYaF69+6tzZs36/Tp0xe8hCVJbrdbbdu29Vy6Od+5oSAzM1PLli3T6dOntWPHDg0dOlSRkZFq27attm/frqioKM92DXXu5z5r+/btmjlzpjp27Kjf/va3at26tVq0aKG1a9fqs88+a/A5zlXXHCbuFwGaBmEHQK0SEhLkdrsVHx+vpKSkf7t9z5499d5776myslKFhYWKi4tTRkbGBfe54oor9OOPP6pTp07/drQkMzNTTqdT69ev15EjRzyhpmPHjtqxY4eioqKUmJio6Ojoen/GC/n8889ls9k0efJkz11h0i9PRT5fU9xaHhcXp0OHDtVYXlpa6vdzAaZjzg6AWvXo0UNWq1V5eXk1Rhzcbrd+/vlnr2VZWVmqrq7WJ598oq+++sprsnJdevbsqSNHjuijjz6qse706dNec4Dat2+vFi1a6O2331arVq08dy1lZmaquLhY27Zt8+kSVl2sVqssFotcLpdn2eHDh7Vp06Ya27Zs2dLrEpQ/XHfddSouLtYPP/zgWXb8+PFGjyoBzREjOwBqlZCQoHvuuUcLFy5UWVmZrr/+eoWFhXl+4WdnZ+uOO+7wbJ+WlqaEhAQtXrxY1dXV//YSlvTLnUwbNmzQyy+/rKKiIs8cnAMHDmjDhg2aPHmyrrrqKkm/BIq0tDTt2rVL3bp184ymXH311aqqqlJVVZVPl7Dq0rVrV61YsUJPPPGEevXqpYqKCr3//vtKSEjQjz/+6LVtWlqavvnmG61YsUKtW7dWfHx8rfNtGuKOO+7Qp59+qscee0y3336759bz2NhYHT9+nAcVAg1A2AFQp8GDBysxMVErV67Um2++KemXeTTXXnut59k258rKytKyZcuUkJCgtLS0f3t8q9Wq8ePHa+XKlVq3bp02bdqk0NBQXXHFFRo4cKASExO9tu/YsaN27drlFWrO3h1WWlrq15Gda665RmPGjNHbb7+t1157TfHx8br33nt1+PDhGmHn/vvv10svvaTFixfr9OnT6tOnT6PDTmxsrKZNm6ZXXnlF+fn5stvt6t+/v1q2bKlXXnnF69IagAvjCcoAcAl59dVX9cEHH+j111+vc6IzAG/8TQGAIHX+O7p+/vlnrVu3TpmZmQQdoAG4jAXASA6H44LrQ0NDG/yk5Ytt8uTJ+o//+A9deeWVOnbsmD7++GOdPHlSd911V6BLAy4pXMYCYKTaXtB5rrMv6wxmCxcu1Oeff66ffvpJFotFqampGjZsmK699tpAlwZcUgg7AIz09ddfX3B9TExMra+IAGAewg4AADAaM9wAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEb7/wBRgixhzsSRzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data = results_df, x='review_rating', y='compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs = plt.subplots(1,3, figsize=(12,3))\n",
    "sns.barplot(data = results_df, x='review_rating', y='pos', ax=axs[0])\n",
    "sns.barplot(data = results_df, x='review_rating', y='neu', ax=axs[1])\n",
    "sns.barplot(data = results_df, x='review_rating', y='neg', ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Nuetral')\n",
    "axs[2].set_title('Negative')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta pretrainde model\n",
    "\n",
    "- VADER takes each word seperately\n",
    "- transformer models accounts for words including the context related to other words\n",
    "- Like sentences could have negative words but written as sarcasm & actually its a positive sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-airflow 2.10.3 requires flask<2.3,>=2.2.1, but you have flask 3.0.3 which is incompatible.\n",
      "apache-airflow 2.10.3 requires werkzeug<3,>=2.0, but you have werkzeug 3.0.6 which is incompatible.\n",
      "apache-airflow-providers-fab 1.4.0 requires flask<2.3,>=2.2, but you have flask 3.0.3 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.16.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed typing-extensions-4.12.2\n",
      "Requirement already satisfied: tensorflow in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\iampr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "Successfully installed typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-airflow 2.10.3 requires flask<2.3,>=2.2.1, but you have flask 3.0.3 which is incompatible.\n",
      "apache-airflow 2.10.3 requires werkzeug<3,>=2.0, but you have werkzeug 3.0.6 which is incompatible.\n",
      "apache-airflow-providers-fab 1.4.0 requires flask<2.3,>=2.2, but you have flask 3.0.3 which is incompatible.\n",
      "graphene 3.4.3 requires typing-extensions<5,>=4.7.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "kombu 5.4.2 requires typing-extensions==4.12.2; python_version < \"3.10\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "selenium 4.27.0 requires typing_extensions~=4.9, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "torch 2.4.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host=files.pythonhosted.org\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3201641287460f9bc5147f71c38513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\iampr\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d2b3610a724aa9afbe38e3c508c897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use pretrainer model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fabric is low. Prefer the other leggings that are more durable and look more flattering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.107, 'neu': 0.762, 'pos': 0.132, 'compound': 0.1263}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vader\n",
    "print(example)\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'robert_neg': 0.233379, 'robert_neu': 0.53080153, 'robert_pos': 0.23581943}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#roberta\n",
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'robert_neg':scores[0],\n",
    "    'robert_neu':scores[1],\n",
    "    'robert_pos':scores[2],\n",
    "}\n",
    "\n",
    "scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_robert(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'robert_neg':scores[0],\n",
    "        'robert_neu':scores[1],\n",
    "        'robert_pos':scores[2],\n",
    "    }\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20df1e9c588749d3b3b24391e5092209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list to store results\n",
    "res = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    review_text = row['review_text']\n",
    "    \n",
    "    # Get VADER sentiment scores\n",
    "    score = sia.polarity_scores(review_text)\n",
    "    \n",
    "    # Get RoBERTa sentiment scores\n",
    "    robert_scores = polarity_scores_robert(review_text)\n",
    "    \n",
    "    # Convert row to dictionary and add both VADER and RoBERTa sentiment scores\n",
    "    row_dict = row.to_dict()  # Convert the row to a dictionary\n",
    "    row_dict.update({\n",
    "        'neg': score['neg'],\n",
    "        'neu': score['neu'],\n",
    "        'pos': score['pos'],\n",
    "        'compound': score['compound'],\n",
    "        **robert_scores  # Add RoBERTa scores to the row_dict\n",
    "    })\n",
    "    \n",
    "    # Append the updated dictionary to the results list\n",
    "    res.append(row_dict)\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>username</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>review_date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>robert_neg</th>\n",
       "      <th>robert_neu</th>\n",
       "      <th>robert_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>So good!</td>\n",
       "      <td>Very form fitting, soft material. I recommend!</td>\n",
       "      <td>Lily C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.024316</td>\n",
       "      <td>0.974192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Fits nicely I went up a size because I don’t l...</td>\n",
       "      <td>Perfect they have the right amount of stretch ...</td>\n",
       "      <td>KIM C</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.986952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Love them</td>\n",
       "      <td>A tip I got in store was that the new sizing f...</td>\n",
       "      <td>Amanda M</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>0.989321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Super comfortable and so soft</td>\n",
       "      <td>Everything was amazing. I wish the pants game ...</td>\n",
       "      <td>simran G</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.156650</td>\n",
       "      <td>0.260293</td>\n",
       "      <td>0.583056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>Size 14 and fit a size 10</td>\n",
       "      <td>Jenesis V</td>\n",
       "      <td>BUTTER New Cheeky Flare Hi-Rise Legging</td>\n",
       "      <td>Golden</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/butter-n...</td>\n",
       "      <td>activeWear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>0.802656</td>\n",
       "      <td>0.142526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect Bag</td>\n",
       "      <td>This bag is great for everything from everyday...</td>\n",
       "      <td>Kristie H</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.987598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>Curator Bag is to die 4</td>\n",
       "      <td>Love!! Simple as that. You can dress it up and...</td>\n",
       "      <td>Trystan C</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>0.930351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5</td>\n",
       "      <td>Great everyday bag!</td>\n",
       "      <td>I've gotten so many compliments already! It's ...</td>\n",
       "      <td>Darine D</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.991163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it!!</td>\n",
       "      <td>Love everything about this bag!</td>\n",
       "      <td>Melissa G</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.985607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4</td>\n",
       "      <td>Love the bag, some flaws</td>\n",
       "      <td>The bag itself is sooo cute, and fits so much ...</td>\n",
       "      <td>Lazaya V</td>\n",
       "      <td>curator bigger bag</td>\n",
       "      <td>Babaton</td>\n",
       "      <td>https://www.aritzia.com/us/en/product/curator-...</td>\n",
       "      <td>accessory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.297192</td>\n",
       "      <td>0.557133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_rating                                              title  \\\n",
       "0                5                                           So good!   \n",
       "1                5  Fits nicely I went up a size because I don’t l...   \n",
       "2                5                                          Love them   \n",
       "3                5                      Super comfortable and so soft   \n",
       "4                5                                              Great   \n",
       "..             ...                                                ...   \n",
       "495              5                                        Perfect Bag   \n",
       "496              5                            Curator Bag is to die 4   \n",
       "497              5                                Great everyday bag!   \n",
       "498              5                                          Love it!!   \n",
       "499              4                           Love the bag, some flaws   \n",
       "\n",
       "                                           review_text   username  \\\n",
       "0       Very form fitting, soft material. I recommend!     Lily C   \n",
       "1    Perfect they have the right amount of stretch ...      KIM C   \n",
       "2    A tip I got in store was that the new sizing f...   Amanda M   \n",
       "3    Everything was amazing. I wish the pants game ...   simran G   \n",
       "4                            Size 14 and fit a size 10  Jenesis V   \n",
       "..                                                 ...        ...   \n",
       "495  This bag is great for everything from everyday...  Kristie H   \n",
       "496  Love!! Simple as that. You can dress it up and...  Trystan C   \n",
       "497  I've gotten so many compliments already! It's ...   Darine D   \n",
       "498                    Love everything about this bag!  Melissa G   \n",
       "499  The bag itself is sooo cute, and fits so much ...   Lazaya V   \n",
       "\n",
       "                                product_name    brand  \\\n",
       "0    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "1    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "2    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "3    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "4    BUTTER New Cheeky Flare Hi-Rise Legging   Golden   \n",
       "..                                       ...      ...   \n",
       "495                       curator bigger bag  Babaton   \n",
       "496                       curator bigger bag  Babaton   \n",
       "497                       curator bigger bag  Babaton   \n",
       "498                       curator bigger bag  Babaton   \n",
       "499                       curator bigger bag  Babaton   \n",
       "\n",
       "                                                  link    category  price  \\\n",
       "0    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "1    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "2    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "3    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "4    https://www.aritzia.com/us/en/product/butter-n...  activeWear    NaN   \n",
       "..                                                 ...         ...    ...   \n",
       "495  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "496  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "497  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "498  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "499  https://www.aritzia.com/us/en/product/curator-...   accessory    NaN   \n",
       "\n",
       "    scrape_date review_date    neg    neu    pos  compound  robert_neg  \\\n",
       "0    2025-02-06  2025-01-23  0.000  0.642  0.358    0.4199    0.001492   \n",
       "1    2025-02-06  2025-01-06  0.041  0.795  0.163    0.7530    0.001485   \n",
       "2    2025-02-06  2025-01-06  0.053  0.540  0.407    0.9498    0.001805   \n",
       "3    2025-02-06  2025-01-06  0.099  0.680  0.221    0.5574    0.156650   \n",
       "4    2025-02-06  2025-01-06  0.000  0.667  0.333    0.3612    0.054819   \n",
       "..          ...         ...    ...    ...    ...       ...         ...   \n",
       "495  2025-02-06  2024-04-06  0.000  0.667  0.333    0.9699    0.001297   \n",
       "496  2025-02-06  2024-03-06  0.000  0.715  0.285    0.6988    0.009166   \n",
       "497  2025-02-06  2024-03-06  0.000  0.641  0.359    0.9163    0.001225   \n",
       "498  2025-02-06  2025-02-06  0.000  0.471  0.529    0.6696    0.002963   \n",
       "499  2025-02-06  2025-02-06  0.057  0.857  0.086    0.2500    0.145674   \n",
       "\n",
       "     robert_neu  robert_pos  \n",
       "0      0.024316    0.974192  \n",
       "1      0.011563    0.986952  \n",
       "2      0.008875    0.989321  \n",
       "3      0.260293    0.583056  \n",
       "4      0.802656    0.142526  \n",
       "..          ...         ...  \n",
       "495    0.011105    0.987598  \n",
       "496    0.060483    0.930351  \n",
       "497    0.007612    0.991163  \n",
       "498    0.011430    0.985607  \n",
       "499    0.297192    0.557133  \n",
       "\n",
       "[500 rows x 18 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d9f058774545d581209c80b39031ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\iampr\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfff2891635c420c8d32d37929a7f1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f6f3de411c4133a002ebe430f0a375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf237fa10914da09f3090afe3754b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sent_pipeline = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9991377592086792}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pipeline(\"Its the best worst product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "sent_pipeline = pipeline('sentiment-analysis', device=-1)  # Use 'device=0' for GPU, 'device=-1' for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"aritzia_reviews_v1.xlsx\", sheet_name='Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 512\n",
    "\n",
    "# Function to process in batches and handle long reviews\n",
    "def batch_sentiment_analysis(df, batch_size=64):\n",
    "    sentiments = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df['review_text'][i:i+batch_size].tolist()  # Convert Series to List of strings\n",
    "\n",
    "        # Handle reviews that might exceed the token limit\n",
    "        batch = [text[:MAX_TOKENS] for text in batch]  # Truncate to MAX_TOKENS length\n",
    "        \n",
    "        batch_sentiments = sent_pipeline(batch)\n",
    "        sentiments.extend([result['label'] for result in batch_sentiments])\n",
    "    \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply batch sentiment analysis to the entire dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentimental_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_sentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 12\u001b[0m, in \u001b[0;36mbatch_sentiment_analysis\u001b[1;34m(df, batch_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Handle reviews that might exceed the token limit\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     batch \u001b[38;5;241m=\u001b[39m [text[:MAX_TOKENS] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m batch]  \u001b[38;5;66;03m# Truncate to MAX_TOKENS length\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     batch_sentiments \u001b[38;5;241m=\u001b[39m \u001b[43msent_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     sentiments\u001b[38;5;241m.\u001b[39mextend([result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m batch_sentiments])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sentiments\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 159\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\base.py:1283\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1280\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1281\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\base.py:1209\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1208\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:190\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    189\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:978\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    976\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 978\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    988\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:798\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m    794\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask_for_sdpa(\n\u001b[0;32m    795\u001b[0m             attention_mask, embeddings\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    796\u001b[0m         )\n\u001b[1;32m--> 798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:551\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    543\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    544\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    545\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m         output_attentions,\n\u001b[0;32m    549\u001b[0m     )\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:495\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    492\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    498\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:429\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:432\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mff_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 432\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[0;32m    434\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iampr\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply batch sentiment analysis to the entire dataset\n",
    "df['sentimental_analysis'] = batch_sentiment_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
